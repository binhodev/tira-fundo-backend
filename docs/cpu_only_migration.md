# Migra√ß√£o para CPU Apenas

## üìã **Altera√ß√µes Realizadas**

Este documento descreve as mudan√ßas implementadas para remover completamente o suporte GPU e manter apenas o processamento CPU.

### ‚úÖ **Arquivos Modificados**

#### 1. **main.py**

-   ‚úÖ Removidas verifica√ß√µes de `torch.cuda.is_available()`
-   ‚úÖ Info de dispositivo hardcoded para CPU apenas
-   ‚úÖ Logs atualizados para indicar "CPU (for√ßado)"

#### 2. **requirements.txt**

-   ‚úÖ `torch>=1.13.0` - Vers√£o CPU-only (instalada via √≠ndice espec√≠fico)
-   ‚úÖ `torchvision>=0.14.0` - Vers√£o CPU-only (instalada via √≠ndice espec√≠fico)
-   ‚ùå **Problema identificado**: Sufixo `+cpu` n√£o evita download de libs NVIDIA

#### 2.1. **Dockerfiles (Solu√ß√£o para libs NVIDIA)**

**Problema**: Mesmo com `torch+cpu`, o pip baixava:

-   `nvidia_cuda_nvrtc_cu12` (~8.9MB)
-   `nvidia_cudnn_cu12` (~571MB)
-   `nvidia_cufft_cu12` (~200MB)
-   `nvidia_curand_cu12` e outras...

**Solu√ß√£o implementada**:

```dockerfile
# Usar √≠ndice espec√≠fico CPU-only do PyTorch
RUN pip install --no-cache-dir --index-url https://download.pytorch.org/whl/cpu torch torchvision && \
    pip install --no-cache-dir -r requirements.txt
```

#### 3. **Dockerfile.coolify**

-   ‚úÖ Adicionadas vari√°veis de ambiente para for√ßar CPU:
    -   `FORCE_CPU=true`
    -   `TORCH_FORCE_CPU=1`
    -   `PYTORCH_JIT=0`
    -   Configura√ß√µes de threading otimizadas

#### 4. **Documenta√ß√£o**

-   ‚úÖ `docs/about.md` - Configura√ß√£o atualizada para CPU apenas
-   ‚úÖ `docs/production_scale.md` - Removida refer√™ncia a CUDA/MPS

## üîß **Configura√ß√µes CPU**

### **Vari√°veis de Ambiente Aplicadas**

```bash
OMP_NUM_THREADS=1
MKL_NUM_THREADS=1
NUMEXPR_NUM_THREADS=1
OPENBLAS_NUM_THREADS=1
PYTORCH_JIT=0
FORCE_CPU=true
TORCH_FORCE_CPU=1
```

### **Configura√ß√µes PyTorch**

```python
torch.set_num_threads(1)  # Limita threads
torch.set_grad_enabled(False)  # Modo infer√™ncia
```

## üìä **Impactos**

### ‚úÖ **Benef√≠cios**

-   **Compatibilidade**: Funciona em qualquer ambiente
-   **Simplicidade**: Sem depend√™ncias GPU complexas
-   **Estabilidade**: Menos problemas de drivers e vers√µes
-   **Deployment**: Mais f√°cil em containers e cloud

### ‚ö†Ô∏è **Considera√ß√µes**

-   **Performance**: Processamento mais lento que GPU
-   **Recursos**: Maior uso de CPU para tarefas intensivas

## üöÄ **Deploy**

Ap√≥s as mudan√ßas, o projeto:

-   ‚úÖ Funciona apenas com CPU
-   ‚úÖ N√£o tenta detectar ou usar GPU
-   ‚úÖ Tem configura√ß√µes otimizadas para CPU
-   ‚úÖ √â compat√≠vel com qualquer ambiente de deployment

## üîç **Verifica√ß√£o**

Para verificar se as mudan√ßas foram aplicadas corretamente:

1. **Teste local:**

    ```bash
    python main.py
    # Deve mostrar: "üì± Dispositivo: CPU (for√ßado)"
    ```

2. **Endpoint de status:**

    ```
    GET /health/models
    # Deve retornar: "device": "cpu"
    ```

3. **Info de modelos:**
    ```
    GET /models
    # device_info.current_device deve ser "cpu"
    ```
